{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8038d41d-4877-4c80-9640-aa59d3cac8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Text Before Processing:\n",
      " \n",
      "education\n",
      "skills\n",
      "experience\n",
      "projects\n",
      "profiles\n",
      "Sharath Kumar Reddy .\n",
      "Deep Learning and AI Engineer\n",
      "about me\n",
      "Sharath Kumar Reddy is a highly skilled Data Scientist and AI researcher with a Master's degree in Data Science from the University of Houston, specializing in Artificial Intelligence and Machine Learning.\n",
      "With a robust background in developing AI solutions and extensive experience in data analysis, Sharath has successfully deployed multiple AI solutions and conducted comprehensive EDA for various clients. Sharath's technical expertise spans a wide range of programming languages, tools, and machine learning techniques and Large Language Models. In addition to his professional accomplishments, he has led innovative projects and held leadership roles, showcasing his ability to drive impactful technological advancements.\n",
      "Phone\n",
      "+1 (346) 227-3943 / +91 957056365\n",
      "Email\n",
      "skrkapu@gmail.com\n",
      "\n",
      "\n",
      "\n",
      "education\n",
      "Aug 2023 - May 2025\n",
      "Masters in Engineering Data Science\n",
      "Coursework: Artificial Intelligence, Machine Learning, Deep Learning, Neural Networks, Data Analysis and Visualization, DBMT, Big Data Analytics, Cloud Computing\n",
      "2022 - 2023\n",
      "Machine Learning Specialisation\n",
      "Concepts: Supervised and Unsupervised Learning techniques including Regression, Classification, Decision Trees, Random Forest, Clustering, Reinforcement Learning\n",
      "Aug 2018 - May 2022\n",
      "Bachelor of Technology\n",
      "Electronics and Communication Engineering: Digital Image Processing, Signals and Systems\n",
      "skills\n",
      "90%\n",
      "85%\n",
      "90%\n",
      "85%\n",
      "70%\n",
      "75%\n",
      "90%\n",
      "80%\n",
      "85%\n",
      "80%\n",
      "90%\n",
      "70%\n",
      "70%\n",
      "60%\n",
      "experience\n",
      "Jul 2022 - Jul 2023 AI Engineer Deloitte Consulting Hyderabad, India Created data automation product using Python, Apache Airflow to improve speed of updating and up-keeping stakeholder data for over 25 Agencies.\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tDeveloped a fast and versatile ML model with TensorFlow that swiftly identified contradictions across various contexts, processing 1,000 documents in under an hour. \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLeveraged scikit-learn algorithms to predict risk factors with an 87% precision, aiding financial clients in reducing potential losses by up to 10% annually\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tAutomated the transformation of raw audit files into a CDM model using generative AI and NLP methods reducing manual work hours for Audit Analytics Specialists by 70%.\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tCreated 3 automated monitoring systems using Large Language Models and chain of thought prompting to assess an RAG chatbot in production, ensuring consistent performance and relevance of responses.\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tUtilized Python to implement Unsupervised techniques for Anomaly detection of 2TB unstructured data.\n",
      "Jul 2022 - Jul 2023\n",
      "AI Engineer\n",
      "Created data automation product using Python, Apache Airflow to improve speed of updating and up-keeping stakeholder data for over 25 Agencies.\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tDeveloped a fast and versatile ML model with TensorFlow that swiftly identified contradictions across various contexts, processing 1,000 documents in under an hour. \n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tLeveraged scikit-learn algorithms to predict risk factors with an 87% precision, aiding financial clients in reducing potential losses by up to 10% annually\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tAutomated the transformation of raw audit files into a CDM model using generative AI and NLP methods reducing manual work hours for Audit Analytics Specialists by 70%.\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tCreated 3 automated monitoring systems using Large Language Models and chain of thought prompting to assess an RAG chatbot in production, ensuring consistent performance and relevance of responses.\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tUtilized Python to implement Unsupervised techniques for Anomaly detection of 2TB unstructured data.\n",
      "Glance Bengaluru, India Analyzed 10 newly launched games on the app, using Pandas and Common Table Expressions (CTE).\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tImplemented robust data pipelines using SQL and Apache Spark, enhancing data processing speed by 35%.\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tPresented 5+ dashboards & visual reports using Tableau, enabling stakeholders to make data-driven decisions.\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tEngineered deep learning models to analyze user behavior and engagement patterns on the Glance lockscreen application, leading to a 20% increase in personalized content delivery accuracy.\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tDeveloped RESTful APIs using Python to integrate disparate data sources over 5TB of Audit data, facilitating seamless data flow and real-time analytics.\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tDeployed predictive models to forecast user behavior and gaming trends, resulting in a 15% increase in personalized content delivery effectiveness. Jun 2021 - Jun 2022 Data Scientist\n",
      "Analyzed 10 newly launched games on the app, using Pandas and Common Table Expressions (CTE).\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tImplemented robust data pipelines using SQL and Apache Spark, enhancing data processing speed by 35%.\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tPresented 5+ dashboards & visual reports using Tableau, enabling stakeholders to make data-driven decisions.\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tEngineered deep learning models to analyze user behavior and engagement patterns on the Glance lockscreen application, leading to a 20% increase in personalized content delivery accuracy.\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tDeveloped RESTful APIs using Python to integrate disparate data sources over 5TB of Audit data, facilitating seamless data flow and real-time analytics.\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tDeployed predictive models to forecast user behavior and gaming trends, resulting in a 15% increase in personalized content delivery effectiveness.\n",
      "Jun 2021 - Jun 2022\n",
      "Data Scientist\n",
      "Feb 2019 - May 2022 Head of Research and Development Cell Center for Cognitive Activities NIT Durgapur chapter Led a team of 25 members organizers showcasing Assistive Technology projects at TECH MELA, the Annual Fest\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t and Spearheaded a DIY Home-security workshop every year, instructing 100+ freshmen in building IOT projects.\n",
      "Feb 2019 - May 2022\n",
      "Head of Research and Development Cell\n",
      "Led a team of 25 members organizers showcasing Assistive Technology projects at TECH MELA, the Annual Fest\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t and Spearheaded a DIY Home-security workshop every year, instructing 100+ freshmen in building IOT projects.\n",
      "PROJECTS\n",
      "TWEET EMOTION RECOGNITION\n",
      "AI CHATBOT\n",
      "Small Language Model\n",
      "REAL-TIME DOCUMENT INTERACTION SYSTEM\n",
      "HEAD GESTURE CONTROLLED WHEEL-CHAIR\n",
      "Movie Recommendation System\n",
      "DEEP LEARNING POWERED IMAGE SUPER-RESOLUTION\n",
      "AUTOMATED DATA PIPELINE\n",
      "STOCK PRICE PREDICTION\n",
      "profiles\n",
      "© copyright Sharath. design and developed by themesine\n",
      "\n",
      "Skills:\n",
      "Python programming: 90%\n",
      "Machine Learning: 85%\n",
      "Large Language Models: 90%\n",
      "TensorFlow: 85%\n",
      "pyTorch: 70%\n",
      "Keras: 75%\n",
      "Natural Language Processing: 90%\n",
      "SQL: 80%\n",
      "Tableau: 85%\n",
      "Azure/ AWS: 80%\n",
      "ETL Pipelines: 90%\n",
      "Apache Spark: 70%\n",
      "Airflow: 70%\n",
      "Docker/ Kubernetes: 60%\n",
      "Final Processed Text:\n",
      " \n",
      "education\n",
      "skills\n",
      "experience\n",
      "projects\n",
      "profiles\n",
      "Sharath Kumar Reddy .\n",
      "Deep Learning and AI Engineer\n",
      "about me\n",
      "Sharath Kumar Reddy is a highly skilled Data Scientist and AI researcher with a Master's degree in Data Science from the University of Houston, specializing in Artificial Intelligence and Machine Learning.\n",
      "With a robust background in developing AI solutions and extensive experience in data analysis, Sharath has successfully deployed multiple AI solutions and conducted comprehensive EDA for various clients.\n",
      "Sharath's technical expertise spans a wide range of programming languages, tools, and machine learning techniques and Large Language Models.\n",
      "In addition to his professional accomplishments, he has led innovative projects and held leadership roles, showcasing his ability to drive impactful technological advancements.\n",
      "Phone\n",
      "+1 (346) 227-3943 / +91 957056365\n",
      "Email\n",
      "skrkapu@gmail.com\n",
      "\n",
      "\n",
      "\n",
      "education\n",
      "Aug 2023 - May 2025\n",
      "Masters in Engineering Data Science\n",
      "Coursework: Artificial Intelligence, Machine Learning, Deep Learning, Neural Networks, Data Analysis and Visualization, DBMT, Big Data Analytics, Cloud Computing\n",
      "2022 - 2023\n",
      "Machine Learning Specialisation\n",
      "Concepts: Supervised and Unsupervised Learning techniques including Regression, Classification, Decision Trees, Random Forest, Clustering, Reinforcement Learning\n",
      "Aug 2018 - May 2022\n",
      "Bachelor of Technology\n",
      "Electronics and Communication Engineering: Digital Image Processing, Signals and Systems\n",
      "skills\n",
      "90%\n",
      "85%\n",
      "90%\n",
      "85%\n",
      "70%\n",
      "75%\n",
      "90%\n",
      "80%\n",
      "85%\n",
      "80%\n",
      "90%\n",
      "70%\n",
      "70%\n",
      "60%\n",
      "experience\n",
      "Jul 2022 - Jul 2023 AI Engineer Deloitte Consulting Hyderabad, India Created data automation product using Python, Apache Airflow to improve speed of updating and up-keeping stakeholder data for over 25 Agencies.\n",
      "Developed a fast and versatile ML model with TensorFlow that swiftly identified contradictions across various contexts, processing 1,000 documents in under an hour.\n",
      "Leveraged scikit-learn algorithms to predict risk factors with an 87% precision, aiding financial clients in reducing potential losses by up to 10% annually\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tAutomated the transformation of raw audit files into a CDM model using generative AI and NLP methods reducing manual work hours for Audit Analytics Specialists by 70%.\n",
      "Created 3 automated monitoring systems using Large Language Models and chain of thought prompting to assess an RAG chatbot in production, ensuring consistent performance and relevance of responses.\n",
      "Utilized Python to implement Unsupervised techniques for Anomaly detection of 2TB unstructured data.\n",
      "Jul 2022 - Jul 2023\n",
      "AI Engineer\n",
      "Created data automation product using Python, Apache Airflow to improve speed of updating and up-keeping stakeholder data for over 25 Agencies.\n",
      "Developed a fast and versatile ML model with TensorFlow that swiftly identified contradictions across various contexts, processing 1,000 documents in under an hour.\n",
      "Leveraged scikit-learn algorithms to predict risk factors with an 87% precision, aiding financial clients in reducing potential losses by up to 10% annually\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tAutomated the transformation of raw audit files into a CDM model using generative AI and NLP methods reducing manual work hours for Audit Analytics Specialists by 70%.\n",
      "Created 3 automated monitoring systems using Large Language Models and chain of thought prompting to assess an RAG chatbot in production, ensuring consistent performance and relevance of responses.\n",
      "Utilized Python to implement Unsupervised techniques for Anomaly detection of 2TB unstructured data.\n",
      "Glance Bengaluru, India Analyzed 10 newly launched games on the app, using Pandas and Common Table Expressions (CTE).\n",
      "Implemented robust data pipelines using SQL and Apache Spark, enhancing data processing speed by 35%.\n",
      "Presented 5+ dashboards & visual reports using Tableau, enabling stakeholders to make data-driven decisions.\n",
      "Engineered deep learning models to analyze user behavior and engagement patterns on the Glance lockscreen application, leading to a 20% increase in personalized content delivery accuracy.\n",
      "Developed RESTful APIs using Python to integrate disparate data sources over 5TB of Audit data, facilitating seamless data flow and real-time analytics.\n",
      "Deployed predictive models to forecast user behavior and gaming trends, resulting in a 15% increase in personalized content delivery effectiveness.\n",
      "Jun 2021 - Jun 2022 Data Scientist\n",
      "Analyzed 10 newly launched games on the app, using Pandas and Common Table Expressions (CTE).\n",
      "Implemented robust data pipelines using SQL and Apache Spark, enhancing data processing speed by 35%.\n",
      "Presented 5+ dashboards & visual reports using Tableau, enabling stakeholders to make data-driven decisions.\n",
      "Engineered deep learning models to analyze user behavior and engagement patterns on the Glance lockscreen application, leading to a 20% increase in personalized content delivery accuracy.\n",
      "Developed RESTful APIs using Python to integrate disparate data sources over 5TB of Audit data, facilitating seamless data flow and real-time analytics.\n",
      "Deployed predictive models to forecast user behavior and gaming trends, resulting in a 15% increase in personalized content delivery effectiveness.\n",
      "Jun 2021 - Jun 2022\n",
      "Data Scientist\n",
      "Feb 2019 - May 2022 Head of Research and Development Cell Center for Cognitive Activities NIT Durgapur chapter Led a team of 25 members organizers showcasing Assistive Technology projects at TECH MELA, the Annual Fest\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t and Spearheaded a DIY Home-security workshop every year, instructing 100+ freshmen in building IOT projects.\n",
      "Feb 2019 - May 2022\n",
      "Head of Research and Development Cell\n",
      "Led a team of 25 members organizers showcasing Assistive Technology projects at TECH MELA, the Annual Fest\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t and Spearheaded a DIY Home-security workshop every year, instructing 100+ freshmen in building IOT projects.\n",
      "PROJECTS\n",
      "TWEET EMOTION RECOGNITION\n",
      "AI CHATBOT\n",
      "Small Language Model\n",
      "REAL-TIME DOCUMENT INTERACTION SYSTEM\n",
      "HEAD GESTURE CONTROLLED WHEEL-CHAIR\n",
      "Movie Recommendation System\n",
      "DEEP LEARNING POWERED IMAGE SUPER-RESOLUTION\n",
      "AUTOMATED DATA PIPELINE\n",
      "STOCK PRICE PREDICTION\n",
      "profiles\n",
      "© copyright Sharath.\n",
      "design and developed by themesine\n",
      "\n",
      "Skills:\n",
      "Python programming: 90%\n",
      "Machine Learning: 85%\n",
      "Large Language Models: 90%\n",
      "TensorFlow: 85%\n",
      "pyTorch: 70%\n",
      "Keras: 75%\n",
      "Natural Language Processing: 90%\n",
      "SQL: 80%\n",
      "Tableau: 85%\n",
      "Azure/ AWS: 80%\n",
      "ETL Pipelines: 90%\n",
      "Apache Spark: 70%\n",
      "Airflow: 70%\n",
      "Docker/ Kubernetes: 60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/sharath/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "# Load the HTML file\n",
    "html_file_path = 'index.html'\n",
    "\n",
    "with open(html_file_path, 'r', encoding='utf-8') as file:\n",
    "    content = file.read()\n",
    "\n",
    "# Parse HTML using BeautifulSoup\n",
    "soup = BeautifulSoup(content, 'lxml')\n",
    "\n",
    "# Function to extract meaningful text including skills and proficiency levels\n",
    "def extract_meaningful_text(soup):\n",
    "    text = []\n",
    "\n",
    "    # Extract content from specific tags while preserving order and context\n",
    "    for tag in soup.find_all(['h1', 'h2', 'h3', 'p', 'li', 'table', 'strong']):\n",
    "        if tag.name == 'table':\n",
    "            text.append(\" \".join(tag.stripped_strings))  # Tables as combined text\n",
    "        else:\n",
    "            text.append(tag.get_text(separator=' ', strip=True))  # Normal text elements\n",
    "\n",
    "    return \"\\n\".join(text)\n",
    "\n",
    "# Function to extract skills and proficiency levels\n",
    "def extract_skills(soup):\n",
    "    skills_data = []\n",
    "    \n",
    "    # Find all barWrappers that contain the skills information\n",
    "    for bar_wrapper in soup.find_all(class_='barWrapper'):\n",
    "        skill = bar_wrapper.find(class_='progressText').get_text(strip=True)\n",
    "        proficiency = bar_wrapper.find_next('h3').get_text(strip=True)\n",
    "        skills_data.append(f'{skill}: {proficiency}')\n",
    "    \n",
    "    return \"\\n\".join(skills_data)\n",
    "\n",
    "# Extract meaningful text\n",
    "meaningful_text = extract_meaningful_text(soup)\n",
    "\n",
    "# Extract skills and proficiency levels\n",
    "skills_text = extract_skills(soup)\n",
    "\n",
    "# Combine the meaningful text with the skills\n",
    "combined_text = meaningful_text + \"\\n\\nSkills:\\n\" + skills_text\n",
    "\n",
    "# Print combined text before further processing\n",
    "print(\"Combined Text Before Processing:\\n\", combined_text)\n",
    "\n",
    "# Optional further processing with NLTK (if needed)\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Sentence Tokenization\n",
    "sentences = sent_tokenize(combined_text)\n",
    "\n",
    "# Join the sentences back into a single string for use in the model\n",
    "final_text = '\\n'.join(sentences)\n",
    "\n",
    "# Print the final processed text\n",
    "print(\"Final Processed Text:\\n\", final_text)\n",
    "\n",
    "# Optionally save the processed text\n",
    "with open('processed_text_with_skills.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(final_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "161f9bf7-57ea-4d33-81a2-7297b3658844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=512):\n",
    "    \"\"\"Splits text into chunks of a specified size.\"\"\"\n",
    "    chunks = [text[i:i + chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "    return chunks\n",
    "\n",
    "# Load and preprocess your text\n",
    "with open('processed_text_with_skills.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Chunk the text\n",
    "chunks = chunk_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58305fba-a8eb-4729-bf49-0ef5e4fff975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"\\neducation\\nskills\\nexperience\\nprojects\\nprofiles\\nSharath Kumar Reddy .\\nDeep Learning and AI Engineer\\nabout me\\nSharath Kumar Reddy is a highly skilled Data Scientist and AI researcher with a Master's degree in Data Science from the University of Houston, specializing in Artificial Intelligence and Machine Learning.\\nWith a robust background in developing AI solutions and extensive experience in data analysis, Sharath has successfully deployed multiple AI solutions and conducted comprehensive EDA for various cli\",\n",
       " \"ents.\\nSharath's technical expertise spans a wide range of programming languages, tools, and machine learning techniques and Large Language Models.\\nIn addition to his professional accomplishments, he has led innovative projects and held leadership roles, showcasing his ability to drive impactful technological advancements.\\nPhone\\n+1 (346) 227-3943 / +91 957056365\\nEmail\\nskrkapu@gmail.com\\n\\n\\n\\neducation\\nAug 2023 - May 2025\\nMasters in Engineering Data Science\\nCoursework: Artificial Intelligence, Machine Learning, \",\n",
       " 'Deep Learning, Neural Networks, Data Analysis and Visualization, DBMT, Big Data Analytics, Cloud Computing\\n2022 - 2023\\nMachine Learning Specialisation\\nConcepts: Supervised and Unsupervised Learning techniques including Regression, Classification, Decision Trees, Random Forest, Clustering, Reinforcement Learning\\nAug 2018 - May 2022\\nBachelor of Technology\\nElectronics and Communication Engineering: Digital Image Processing, Signals and Systems\\nskills\\n90%\\n85%\\n90%\\n85%\\n70%\\n75%\\n90%\\n80%\\n85%\\n80%\\n90%\\n70%\\n70%\\n60%\\nexpe',\n",
       " 'rience\\nJul 2022 - Jul 2023 AI Engineer Deloitte Consulting Hyderabad, India Created data automation product using Python, Apache Airflow to improve speed of updating and up-keeping stakeholder data for over 25 Agencies.\\nDeveloped a fast and versatile ML model with TensorFlow that swiftly identified contradictions across various contexts, processing 1,000 documents in under an hour.\\nLeveraged scikit-learn algorithms to predict risk factors with an 87% precision, aiding financial clients in reducing potential',\n",
       " ' losses by up to 10% annually\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\tAutomated the transformation of raw audit files into a CDM model using generative AI and NLP methods reducing manual work hours for Audit Analytics Specialists by 70%.\\nCreated 3 automated monitoring systems using Large Language Models and chain of thought prompting to assess an RAG chatbot in production, ensuring consistent performance and relevance of responses.\\nUtilized Python to implement Unsupervised techniques for Anomaly detection of 2TB unstructured data.\\n',\n",
       " 'Jul 2022 - Jul 2023\\nAI Engineer\\nCreated data automation product using Python, Apache Airflow to improve speed of updating and up-keeping stakeholder data for over 25 Agencies.\\nDeveloped a fast and versatile ML model with TensorFlow that swiftly identified contradictions across various contexts, processing 1,000 documents in under an hour.\\nLeveraged scikit-learn algorithms to predict risk factors with an 87% precision, aiding financial clients in reducing potential losses by up to 10% annually\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t',\n",
       " '\\tAutomated the transformation of raw audit files into a CDM model using generative AI and NLP methods reducing manual work hours for Audit Analytics Specialists by 70%.\\nCreated 3 automated monitoring systems using Large Language Models and chain of thought prompting to assess an RAG chatbot in production, ensuring consistent performance and relevance of responses.\\nUtilized Python to implement Unsupervised techniques for Anomaly detection of 2TB unstructured data.\\nGlance Bengaluru, India Analyzed 10 newly la',\n",
       " 'unched games on the app, using Pandas and Common Table Expressions (CTE).\\nImplemented robust data pipelines using SQL and Apache Spark, enhancing data processing speed by 35%.\\nPresented 5+ dashboards & visual reports using Tableau, enabling stakeholders to make data-driven decisions.\\nEngineered deep learning models to analyze user behavior and engagement patterns on the Glance lockscreen application, leading to a 20% increase in personalized content delivery accuracy.\\nDeveloped RESTful APIs using Python to ',\n",
       " 'integrate disparate data sources over 5TB of Audit data, facilitating seamless data flow and real-time analytics.\\nDeployed predictive models to forecast user behavior and gaming trends, resulting in a 15% increase in personalized content delivery effectiveness.\\nJun 2021 - Jun 2022 Data Scientist\\nAnalyzed 10 newly launched games on the app, using Pandas and Common Table Expressions (CTE).\\nImplemented robust data pipelines using SQL and Apache Spark, enhancing data processing speed by 35%.\\nPresented 5+ dashbo',\n",
       " 'ards & visual reports using Tableau, enabling stakeholders to make data-driven decisions.\\nEngineered deep learning models to analyze user behavior and engagement patterns on the Glance lockscreen application, leading to a 20% increase in personalized content delivery accuracy.\\nDeveloped RESTful APIs using Python to integrate disparate data sources over 5TB of Audit data, facilitating seamless data flow and real-time analytics.\\nDeployed predictive models to forecast user behavior and gaming trends, resulting',\n",
       " ' in a 15% increase in personalized content delivery effectiveness.\\nJun 2021 - Jun 2022\\nData Scientist\\nFeb 2019 - May 2022 Head of Research and Development Cell Center for Cognitive Activities NIT Durgapur chapter Led a team of 25 members organizers showcasing Assistive Technology projects at TECH MELA, the Annual Fest\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t and Spearheaded a DIY Home-security workshop every year, instructing 100+ freshmen in building IOT projects.\\nFeb 2019 - May 2022\\nHead of Research and Development Cell\\nLed a tea',\n",
       " 'm of 25 members organizers showcasing Assistive Technology projects at TECH MELA, the Annual Fest\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t and Spearheaded a DIY Home-security workshop every year, instructing 100+ freshmen in building IOT projects.\\nPROJECTS\\nTWEET EMOTION RECOGNITION\\nAI CHATBOT\\nSmall Language Model\\nREAL-TIME DOCUMENT INTERACTION SYSTEM\\nHEAD GESTURE CONTROLLED WHEEL-CHAIR\\nMovie Recommendation System\\nDEEP LEARNING POWERED IMAGE SUPER-RESOLUTION\\nAUTOMATED DATA PIPELINE\\nSTOCK PRICE PREDICTION\\nprofiles\\n© copyright Sharath',\n",
       " '.w\\ndesign and developed by themesine\\n\\nSkills:\\nPython programming: 90%\\nMachine Learning: 85%\\nLarge Language Models: 90%\\nTensorFlow: 85%\\npyTorch: 70%\\nKeras: 75%\\nNatural Language Processing: 90%\\nSQL: 80%\\nTableau: 85%\\nAzure/ AWS: 80%\\nETL Pipelines: 90%\\nApache Spark: 70%\\nAirflow: 70%\\nDocker/ Kubernetes: 60%']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c7eefe5-49bf-4878-abf7-d4a94b3846b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e827f8e34ac43cd96f51bfb8c23aa29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb645489469944f4a38f3aa3946ceab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c456e0d617bc45eca9883c4f7d3d7a58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9a796b4f894366820e74c196a20326",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d14630135e7c45d7a94f38d323183286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "def get_embeddings(texts):\n",
    "    inputs = tokenizer(texts, return_tensors='pt', truncation=True, padding=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).numpy()\n",
    "\n",
    "chunk_embeddings = get_embeddings(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3019d68-a056-4f34-ac1b-8334b13019ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.20125815,  0.16343354,  0.09499156, ..., -0.12452382,\n",
       "        -0.07311866, -0.11838534],\n",
       "       [-0.17397119,  0.19378352,  0.17293273, ..., -0.12043826,\n",
       "        -0.03148735, -0.00307511],\n",
       "       [-0.14250673,  0.20955324,  0.34830558, ..., -0.24934298,\n",
       "        -0.1118788 ,  0.09516998],\n",
       "       ...,\n",
       "       [-0.32565552, -0.16048494,  0.35779005, ..., -0.19769624,\n",
       "         0.05380083, -0.20772623],\n",
       "       [-0.17981175, -0.0547062 ,  0.4001052 , ..., -0.14094925,\n",
       "        -0.0481856 , -0.04774047],\n",
       "       [-0.35822657,  0.02969653,  0.03372635, ..., -0.30330613,\n",
       "        -0.14249526,  0.16670467]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8df71cff-80be-411d-90da-c7d5e4572709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "index = faiss.IndexFlatL2(chunk_embeddings.shape[1])\n",
    "index.add(chunk_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d6a2fc9f-6ccb-4347-af9e-ad08166b237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Do you have experience in BERT models?\"\n",
    "query_embedding = get_embeddings([query])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4063fd65-e224-4763-aa63-fd8fc2497649",
   "metadata": {},
   "outputs": [],
   "source": [
    "D, I = index.search(query_embedding, k=1)\n",
    "relevant_chunk = chunks[I[0][0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5007479-4466-4df8-a898-64e62b43f02d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: m of 25 members organizers\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load a question-answering pipeline\n",
    "qa_pipeline = pipeline(\"question-answering\")\n",
    "\n",
    "# Generate the answer from the relevant chunk\n",
    "answer = qa_pipeline(question=query, context=relevant_chunk)\n",
    "\n",
    "print(f\"Answer: {answer['answer']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89a4f63-5a4c-45f5-bd6d-b5397413015e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c4f26d-b3a8-44c0-a71e-3e4cf0be63c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
